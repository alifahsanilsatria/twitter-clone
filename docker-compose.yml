services:
  postgresql:
    image: postgres:14.10
    container_name: postgresql
    environment:
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASS}
      - POSTGRES_DB=${DB_NAME}
    ports:
      - ${DB_HOST_PORT}:5432
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks:
      - twitter_network
    healthcheck:  
      test: [ "CMD", "pg_isready" ]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    env_file:
      - .env

  redis:
    image: redis:7.2
    container_name: redis
    ports:
      - ${REDIS_HOST_PORT}:6379
    volumes:
      - redisdata:/var/lib/redis/data
    command: /bin/sh -c "redis-server --requirepass ${REDIS_PASS}"
    networks:
      - twitter_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 2s
      retries: 10 
    restart: unless-stopped
    env_file:
      - .env

  api-golang:
    image: api-golang
    container_name: backend
    build:
      context: .
      dockerfile: ./Dockerfile
    ports:
      - ${TWITTER_CLONE_HOST_PORT}:9090
    networks:
      - twitter_network
    restart: unless-stopped
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
      zipkin-collector:
        condition: service_healthy
    env_file:
      - .env

  zipkin-collector:
    image: openzipkin/zipkin-slim:3
    container_name: zipkin-collector
    environment:
      - STORAGE_TYPE=elasticsearch
      # Point the zipkin at the storage backend
      - ES_HOSTS=${ZIPKIN_ES_HOSTS}
      # Uncomment to see requests to and from elasticsearch
      - ES_HTTP_LOGGING=BODY
       # Uncomment to increase heap size
      - JAVA_OPTS=-Xms1024m -Xmx1024m -XX:+ExitOnOutOfMemoryError
    ports:
      - ${ZIPKIN_COLLECTOR_HOST_PORT}:9411
    depends_on:
      zipkin-elasticsearch:
        condition: service_healthy
    networks:
      - twitter_network
    env_file:
      - .env

  zipkin-elasticsearch:
    image: ghcr.io/openzipkin/zipkin-elasticsearch8:3.1.1
    container_name: zipkin-elasticsearch
    volumes:
      - distributed-tracing-elastic-data:/elasticsearch
    ports:    
      - ${ZIPKIN_ES_HOST_PORT}:9200
    networks:
      - twitter_network
    env_file:
      - .env

  logstash-elasticsearch:
    image: elasticsearch:7.17.18
    container_name: elasticsearch
    restart: always
    volumes:
      - distributed-log-elastic-data:/usr/share/elasticsearch/data/
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
      discovery.type: single-node
    healthcheck:
      test: ["CMD-SHELL", "echo 'Hello from elastic' || exit 1"]
      interval: 1s
      timeout: 2s
      retries: 10 
    ports:
      - ${LOGSTASH_ES_HOST_PORT}:9200
    networks:
      - twitter_network
    env_file:
      - .env

  logstash:
    image: logstash:7.16.2
    container_name: logstash
    restart: always
    volumes:
      - distributed-log-logstash-conf:/logstash
      - /var/log/api-golang.log:/var/log/api-golang.log
    command: logstash -f /logstash/logstash.conf
    depends_on:
      logstash-elasticsearch:
        condition: service_healthy
    ports:
      - ${LOGSTASH_HOST_PORT}:9600
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m" 
    networks:
      - twitter_network
    env_file:
      - .env

  kibana:
    image: kibana:7.16.2
    container_name: kibana
    restart: always
    volumes:
      - distributed-log-kibana:/usr/share/kibana
    ports:
      - ${KIBANA_HOST_PORT}:5601
    environment:
      - ELASTICSEARCH_URL=${LOGSTASH_ES_HOST}
    depends_on:
      logstash-elasticsearch:
        condition: service_healthy
    networks:
      - twitter_network
    env_file:
      - .env

  prometheus:
    image: prom/prometheus:v2.51.0
    container_name: prometheus
    ports:
      - ${PROMETHEUS_HOST_PORT}:9100
    command:
      - --config.file=/etc/prometheus/prometheus.yml
    volumes:
      - apm-prometheus:/etc/prometheus:ro
    depends_on:
      - cadvisor
    networks:
      - twitter_network
    env_file:
      - .env
  
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.49.1
    container_name: cadvisor
    ports:
      - ${CADVISOR_HOST_PORT}:8080
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
      api-golang:
        condition: service_started
    networks:
      - twitter_network
    env_file:
      - .env

  grafana:
    image: grafana/grafana-enterprise:10.3.5
    container_name: grafana
    restart: unless-stopped
    # if you are running as root then set it to 0
    # else find the right id with the id -u command
    user: '0'
    ports:
      - ${GRAFANA_HOST_PORT}:3000
    # adding the mount volume point which we create earlier
    volumes:
      - apm-grafana:/var/lib/grafana
    networks:
      - twitter_network
    env_file:
      - .env
    
volumes:
  pgdata:
  redisdata:
  distributed-tracing-elastic-data:
  distributed-log-elastic-data:
  distributed-log-logstash-conf:
  distributed-log-logstash-log:
  distributed-log-kibana:
  apm-prometheus:
  apm-grafana:

networks:
  twitter_network: